{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPE5BBTY1bSfXFWfOzhqfVN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjaminbrown038/PyTorch/blob/main/image_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Image Data Using PyTorch Modules\n",
        "\n",
        "-  MNIST Dataset\n",
        "      \n",
        "      - https://pytorch.org/vision/main/datasets.html\n",
        "\n",
        "      - PyTorch Dataset Object\n",
        "\n",
        "      - PyTorch DataLoader Object\n",
        "\n",
        "-  CIFAR Dataset\n",
        "\n",
        "      - https://pytorch.org/vision/main/datasets.html\n",
        "\n",
        "      - PyTorch Dataset Object\n",
        "\n",
        "      - PyTorch DataLoader Object\n",
        "\n",
        "1. Used the torchvision module to import 2 seperate datasets to verify image model architectures in python by compiling model objects, creating a training loop, and running a script that accepts image data of shape (1,28,28); while using optimizers, loss functions, and specific batch sizes increase accuracy.\n",
        "\n",
        "\n",
        "2. Used the DataLoader module in PyTorch to convert the dataset object in python (from pytorch) to shuffle images and create batches of images.\n",
        "\n",
        "\n",
        "### [Imports](#imports)\n",
        "\n",
        "The DataLoader module is the only module required import from **PyTorch** library to accept experiments for establishing a foundation for the principles for programming in machine learning.\n",
        "\n",
        "\n",
        "### [Data](#data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Below are the libraries used in PyTorch Image Data Modules to test neural networks."
      ],
      "metadata": {
        "id": "tQ0EMVb2y8mQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports\n",
        "<a name=\"imports\"></a>\n"
      ],
      "metadata": {
        "id": "BbVE67qfz0kF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "APphs1Hzy8w8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### MNIST Training Dataset\n",
        "\n",
        "1. Used the root optional input in this module to specify where to store the data once imported.\n",
        "\n",
        "2. Used the download option to specify downloading the dataset from PyTorch server.\n",
        "\n",
        "3. Used the train option to True for training data and False for testing data to verify the amount of images that were imported from PyTorch server.\n",
        "\n",
        "4. Used the transform option and the transforms library to specify the specific transformations to make to the dataset before being accepted into the model.\n",
        "\n",
        "<a name=\"data\"></a>"
      ],
      "metadata": {
        "id": "N3HmtObWy83_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "mnist_train = torchvision.datasets.MNIST(root = '/data', download = True,train = True,transform = transforms.ToTensor())\n",
        "mnist_test = torchvision.datasets.MNIST(root = '/data', download = True, train = False, transform = transforms.ToTensor())"
      ],
      "metadata": {
        "id": "r4bY6SiLy8-e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train"
      ],
      "metadata": {
        "id": "Tj3uVb7WHOfT",
        "outputId": "76055490-c38f-43a1-f48c-722fa76a6018",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST Training DataLoader\n",
        "\n",
        "1. Using batch size to specify how to split up the dataset.\n",
        "\n",
        "2. Using shuffle to option to specify splitting up the data.\n",
        "\n",
        "Accepts the dataset object that PyTorch made in the previous step for additional transformations and steps applied to dataset before being accepted into a model."
      ],
      "metadata": {
        "id": "ZK3zhvOh00lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train_dataloader = DataLoader(mnist_train,batch_size = 64, shuffle = True)\n",
        "mnist_test_dataloader = DataLoader(mnist_test,batch_size = 64, shuffle = True)"
      ],
      "metadata": {
        "id": "B8A6yyPZ00rc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train_dataloader"
      ],
      "metadata": {
        "id": "eQ1Lc1IlIHcz",
        "outputId": "6144c102-445f-49a5-be91-f1c9f745d8d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fe31dbde740>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST Training Dataset for *Pretrained Models*\n",
        "\n",
        "1. Used the root optional input in this module to specify where to store the data once imported.\n",
        "\n",
        "2. Used the download option to specify downloading the dataset from PyTorch server.\n",
        "\n",
        "3. Used the train option to True for training data and False for testing data to verify the amount of images that were imported from PyTorch server.\n",
        "\n",
        "4. Used the transform option and the transforms library to specify the specific transformations to make to the dataset before being accepted into the model. We used the ToTensor and Grayscale modules because the pretrained models only accept grayscale images."
      ],
      "metadata": {
        "id": "_JACg_Tk00w7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train1 = torchvision.datasets.MNIST(root = '/data', download = True,train = True,transform = transforms.Compose([transforms.ToTensor(),transforms.Grayscale(3)]))\n",
        "mnist_test1 = torchvision.datasets.MNIST(root = '/data', download = True, train = False, transform = transforms.Compose([transforms.ToTensor(),transforms.Grayscale(3)]))"
      ],
      "metadata": {
        "id": "bI_LIAac002H"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train1"
      ],
      "metadata": {
        "id": "NrAd8Jo0IJd8",
        "outputId": "a48c631a-ed58-4cdc-fafb-6e1c164ba23e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Grayscale(num_output_channels=3)\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST Training DataLoader for *Pretrained Model*\n",
        "\n",
        "1. Using batch size to specify how to split up the dataset.\n",
        "\n",
        "2. Using shuffle to option to specify splitting up the data.\n",
        "\n",
        "Accepts the grayscaledataset object that PyTorch made in the previous step for additional transformations and steps applied to dataset before being accepted into a model."
      ],
      "metadata": {
        "id": "37hy609A008L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train_dataloader1 = DataLoader(mnist_train,batch_size = 64,shuffle = True)\n",
        "mnist_test_dataloader1 = DataLoader(mnist_test,batch_size = 64, shuffle = True)"
      ],
      "metadata": {
        "id": "49P8YMWH01BD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train_dataloader1"
      ],
      "metadata": {
        "id": "dQyEiRdPILBb",
        "outputId": "94760a84-9684-4b0a-c350-65c478839e26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fe31dbdf880>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR Training Dataset\n",
        "\n",
        "1. Used the root optional input in this module to specify where to store the data once imported.\n",
        "\n",
        "2. Used the download option to specify downloading the dataset from PyTorch server.\n",
        "\n",
        "3. Used the train option to True for training data and False for testing data to verify the amount of images that were imported from PyTorch server.\n",
        "\n",
        "4. Used the transform option and the transforms library to specify the specific transformations to make to the dataset before being accepted into the model.\n"
      ],
      "metadata": {
        "id": "dqVTF_uR01Gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_train = torchvision.datasets.MNIST(root = '/data', download = True, train = True)\n",
        "cifar_test = torchvision.datasets.MNIST(root = '/data',download = True, train = False)"
      ],
      "metadata": {
        "id": "GYeb6eb301L-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_train"
      ],
      "metadata": {
        "id": "t1T78QssIMkL",
        "outputId": "418e741d-354f-4fbb-b0b5-ac671d68fd81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /data\n",
              "    Split: Train"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR Training DataLoader\n",
        "\n",
        "1. Using batch size to specify how to split up the dataset.\n",
        "\n",
        "2. Using shuffle to option to specify splitting up the data.\n",
        "\n",
        "Accepts the dataset object that PyTorch made in the previous step for additional transformations and steps applied to dataset before being accepted into a model."
      ],
      "metadata": {
        "id": "hXwGNMZ60-fK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_train_dataloader = DataLoader(mnist_train, batch_size = 64, shuffle = True)\n",
        "cifar_test_dataloader = DataLoader(mnist_test, batch_size = 64, shuffle = True)"
      ],
      "metadata": {
        "id": "iqtHu8NN0-rj"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_train_dataloader"
      ],
      "metadata": {
        "id": "gWo_08J4IN_8",
        "outputId": "29b6c1c7-f728-494c-aedb-3adf93ee15e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fe31dbdc130>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OURW7lEVLBm_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}